{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.layers import Dense, Input\n",
    "from keras import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDf = pd.read_csv('/import/scratch/mdl31/ctrdata/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't want to onehot encode these variable sbut don't want to delete either\n",
    "hourSeries = trainDf['hour']\n",
    "idSeries = trainDf['id']\n",
    "ySeries = trainDf['click']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDf = trainDf.drop('hour', axis = 1)\n",
    "trainDf = trainDf.drop('id', axis = 1)\n",
    "trainDf = trainDf.drop('click', axis = 1)\n",
    "\n",
    "\n",
    "# Removing these as there are too many categories\n",
    "# TODO could try to group into broad categories, e.g. take top 5 commonest categroies, and put the rest under 'other' token\n",
    "trainDf = trainDf.drop('device_id', axis = 1)\n",
    "trainDf = trainDf.drop('device_ip', axis = 1)\n",
    "trainDf = trainDf.drop('device_model', axis = 1)\n",
    "trainDf = trainDf.drop('site_id', axis = 1)\n",
    "trainDf = trainDf.drop('site_domain', axis = 1)\n",
    "trainDf = trainDf.drop('app_id', axis = 1)\n",
    "trainDf = trainDf.drop('app_domain', axis = 1)\n",
    "trainDf = trainDf.drop('C14', axis = 1)\n",
    "trainDf = trainDf.drop('C17', axis = 1)\n",
    "trainDf = trainDf.drop('C19', axis = 1) # only 68 values so might want\n",
    "trainDf = trainDf.drop('C20', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C1\n",
      "7\n",
      "banner_pos\n",
      "7\n",
      "site_category\n",
      "26\n",
      "app_category\n",
      "36\n",
      "device_type\n",
      "5\n",
      "device_conn_type\n",
      "4\n",
      "C15\n",
      "8\n",
      "C16\n",
      "9\n",
      "C18\n",
      "4\n",
      "C21\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "# This cell was used to check number of categories in each diemnsion,\n",
    "# in order to choose which to remove\n",
    "combs = 1\n",
    "for col in trainDf.columns:\n",
    "    print(col)\n",
    "    length = len(trainDf[col].value_counts())\n",
    "    combs *= length\n",
    "    print(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encode the variables\n",
    "trainDf = pd.get_dummies(trainDf, columns = trainDf.columns, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainDf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reintroduce the hour data\n",
    "trainDf['hour'] = hourSeries\n",
    "del hourSeries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create validation dataset\n",
    "x_train, x_val, y_train, y_val = train_test_split(trainDf, ySeries, stratify = ySeries)\n",
    "del trainDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Now to start building a model\\nfrom sklearn.linear_model import SGDClassifier\\nmodel = SGDClassifier(max_iter=2, loss='hinge')\\nmodel.fit(x_train,y_train)\\ny_train_pred = model.pred(x_train)\\naccuracy_score(y_train,y_train_pred)\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Now to start building a model\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "model = SGDClassifier(max_iter=2, loss='hinge')\n",
    "model.fit(x_train,y_train)\n",
    "y_train_pred = model.pred(x_train)\n",
    "accuracy_score(y_train,y_train_pred)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /import/linux/python/3.6.6/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1024)              161792    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 818,177\n",
      "Trainable params: 818,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create Neural Network model\n",
    "nnModel = Sequential()\n",
    "nnModel.add(Dense(1024, input_shape=(len(x_train.columns),), activation='relu'))\n",
    "nnModel.add(Dense(512, activation='relu'))\n",
    "nnModel.add(Dense(256, activation='relu'))\n",
    "nnModel.add(Dense(1,   activation='sigmoid'))\n",
    "nnModel.compile(optimizer='adam', metrics=['accuracy'],loss='binary_crossentropy')\n",
    "nnModel.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "30321725/30321725 [==============================] - 1088s 36us/step - loss: 13.2353 - acc: 0.1698\n",
      "Epoch 2/2\n",
      "30321725/30321725 [==============================] - 1076s 35us/step - loss: 13.2353 - acc: 0.1698\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f584e9e0c50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnModel.fit(x_train,y_train, batch_size = 256, epochs = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I ran out of time to take this any further (time limit was set to 3hrs). Model does not have better accuracy than simply guessing that the user will not click. This was the case even when trained for much larger numbers of epochs.\n",
    " Next steps I would take:\n",
    "- Address class imbalance: use class weights or split data to have even classes. This should encourage better classification\n",
    "- Try a different model or a more complex neural network to resolve the underfitting\n",
    "- Try retaining the features that were deleted\n",
    "- try hashing rather than onehot encoding the categorical data\n",
    "- If i get reasonable training results, train the model with validation data supplied to know when to stop training the NN, use a checkpoint to save the model and to do early stopping\n",
    "- If i get reasonable training results, then evaluate against the test data to get an estimation of accuracy. Interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ctr",
   "language": "python",
   "name": "ctr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
